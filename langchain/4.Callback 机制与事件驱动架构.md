# ç¬¬4ç« ï¼šCallback æœºåˆ¶ä¸äº‹ä»¶é©±åŠ¨æ¶æ„

# å‰è¨€
å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯é²«å°é±¼ã€‚æ˜¯ä¸€å`ä¸å†™å‰ç«¯ä»£ç `çš„å‰ç«¯å·¥ç¨‹å¸ˆï¼Œçƒ­è¡·äºåˆ†äº«éå‰ç«¯çš„çŸ¥è¯†ï¼Œå¸¦é¢†åˆ‡å›¾ä»”é€ƒç¦»åˆ‡å›¾åœˆå­ï¼Œæ¬¢è¿å…³æ³¨æˆ‘ï¼Œå¾®ä¿¡å…¬ä¼—å·ï¼š`ã€Šé²«å°é±¼ä¸æ­£ç»ã€‹`ã€‚æ¬¢è¿ç‚¹èµã€æ”¶è—ã€å…³æ³¨ï¼Œä¸€é”®ä¸‰è¿ï¼ï¼

## ğŸ¯ æœ¬ç« å­¦ä¹ ç›®æ ‡
- å…¨é¢ç†è§£ LangChain.js çš„å›è°ƒï¼ˆCallbackï¼‰ä½“ç³»ï¼šç”Ÿå‘½å‘¨æœŸäº‹ä»¶ã€åµŒå¥—é“¾è·¯ã€Run ID ä¸ä¸Šä¸‹æ–‡
- æŒæ¡æµå¼è¾“å‡ºï¼ˆStreamingï¼‰ã€è¿›åº¦ä¸ŠæŠ¥ï¼ˆProgressï¼‰ã€æŒ‡æ ‡è§‚æµ‹ï¼ˆMetricsï¼‰çš„å®ç°æ–¹å¼
- èƒ½å¤Ÿè‡ªå®šä¹‰ `CallbackHandler`ï¼Œä¸ Runnableã€Memoryã€Agentã€Toolã€Retriever ç­‰æ¨¡å—ååŒ
- åœ¨ Next.js ä¸­å®ç° SSE/WebSocket å®æ—¶æ¨é€ï¼›åœ¨å‰ç«¯å®ç°æ‰“å­—æœºæ•ˆæœã€å–æ¶ˆä¸é‡è¯•
- ç”¨ LangSmith/è‡ªå»ºæ—¥å¿—å®ç°é“¾è·¯è¿½è¸ªã€é”™è¯¯å‘Šè­¦ã€æˆæœ¬ç›‘æ§ä¸ A/B è¯„æµ‹
- é€šè¿‡ä¸¤ä¸ªå®æˆ˜é¡¹ç›®å®Œæˆä»åç«¯äº‹ä»¶é©±åŠ¨åˆ°å‰ç«¯å®æ—¶ UI çš„é—­ç¯è½åœ°

---

## ğŸ“– ç†è®ºï¼šCallback ä¸äº‹ä»¶é©±åŠ¨ï¼ˆçº¦ 30%ï¼‰

### 4.1 ä¸ºä»€ä¹ˆéœ€è¦ Callback
- LLM æ¨ç†æ˜¯â€œé»‘ç®±â€ä¸â€œé•¿è€—æ—¶â€çš„ç»“åˆï¼Œå›è°ƒå¯ä»¥æš´éœ²è¿‡ç¨‹ã€æå‡å¯è§‚æµ‹æ€§
- å¤æ‚é“¾è·¯ï¼ˆPrompt â†’ LLM â†’ Parser â†’ Tool â†’ Retrieverï¼‰çš„æ¯ä¸€æ­¥éƒ½éœ€è¦æ—¥å¿—ã€æŒ‡æ ‡ä¸é”™è¯¯æ•æ‰
- æµå¼è¾“å‡ºéœ€è¦â€œæŒ‰ token æ¨é€â€ï¼Œå›è°ƒæ˜¯å¤©ç„¶è½½ä½“

### 4.2 ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ï¼ˆæ¦‚å¿µæ€»è§ˆï¼‰
LangChain.js åœ¨ä¸åŒå±‚æä¾›äº†ä¸°å¯Œçš„å›è°ƒé’©å­ï¼ˆå…·ä½“å‘½åä»¥ç‰ˆæœ¬ä¸ºå‡†ï¼‰ï¼š
- LLM çº§ï¼š
  - `handleLLMStart` / `handleLLMNewToken` / `handleLLMEnd` / `handleLLMError`
- Chain/Runnable çº§ï¼š
  - `handleChainStart` / `handleChainEnd` / `handleChainError`
  - `handleRunnableStart` / `handleRunnableEnd` / `handleRunnableError`
- Tool çº§ï¼š
  - `handleToolStart` / `handleToolEnd` / `handleToolError`
- Retriever/Loader çº§ï¼š
  - `handleRetrieverStart` / `handleRetrieverEnd` / `handleRetrieverError`

äº‹ä»¶ä¸­é€šå¸¸ä¼šåŒ…å«ï¼š
- `runId`ï¼ˆä¸€æ¬¡è°ƒç”¨çš„å”¯ä¸€ IDï¼‰ä¸ `parentRunId`ï¼ˆåµŒå¥—é“¾è·¯ï¼‰
- `tags`ã€`metadata`ï¼ˆè‡ªå®šä¹‰æ ‡è®°ï¼‰
- è¾“å…¥/è¾“å‡ºç‰‡æ®µã€token ç”¨é‡ã€è€—æ—¶ç­‰

### 4.3 åµŒå¥—ä¸Runæ ‘ï¼ˆRun Treeï¼‰
å½“ä¸€ä¸ª Runnable ä¸­åˆè°ƒç”¨äº†å¤šä¸ªå­ Runnable/Tools æ—¶ï¼Œå›è°ƒäº‹ä»¶ä¼šå½¢æˆä¸€æ£µæ ‘ï¼š
```
invoke (runId: A)
 â”œâ”€ Prompt.format (runId: B, parent: A)
 â”œâ”€ LLM.invoke (runId: C, parent: A)
 â”‚   â”œâ”€ token#1
 â”‚   â”œâ”€ token#2
 â”‚   â””â”€ ...
 â””â”€ OutputParser.parse (runId: D, parent: A)
```
è¿™è®©æˆ‘ä»¬å¯ä»¥ç²¾å‡†å®šä½æ€§èƒ½ç“¶é¢ˆä¸é”™è¯¯èŠ‚ç‚¹ã€‚

### 4.4 äº‹ä»¶é©±åŠ¨æ¶æ„ä¸­çš„è§’è‰²
- ç”Ÿäº§è€…ï¼šLLMã€Retrieverã€Tool ç­‰æ¨¡å—ä¸æ–­äº§å‡ºäº‹ä»¶
- æ±‡èšå™¨ï¼šCallbackHandler/Logger å°†äº‹ä»¶èšåˆæˆç»“æ„åŒ–æ—¥å¿—/æŒ‡æ ‡
- æ¶ˆè´¹è€…ï¼šUI è¿›åº¦æ¡ã€æ‰“å­—æœºæ•ˆæœã€æŠ¥è­¦å™¨ã€ç›‘æ§çœ‹æ¿

### 4.5 å…³é”®è®¾è®¡ç‚¹
- å¯æ’æ‹”ï¼šå›è°ƒåº”å¯è‡ªç”±å¼€å…³ä¸ç»„åˆï¼Œä¸å½±å“æ ¸å¿ƒé€»è¾‘
- å¼‚æ­¥å®‰å…¨ï¼šå›è°ƒåº”å¿«é€Ÿã€å¹‚ç­‰ï¼Œé¿å…é˜»å¡ä¸»æ‰§è¡Œ
- éšç§ä¸åˆè§„ï¼šé¿å…æ—¥å¿—ä¸­æ³„éœ²æ•æ„Ÿä¿¡æ¯ï¼ˆAPI Keyã€ç”¨æˆ·éšç§ï¼‰
- æˆæœ¬æ„è¯†ï¼šåªè®°å½•å¿…è¦çš„ä¿¡æ¯ï¼›åœ¨å‹æµ‹/ç”Ÿäº§ä¸å¼€å‘æ¨¡å¼ä¸­å·®å¼‚åŒ–å¼€å…³

---

## ğŸ§© åŸºç¡€åˆ°è¿›é˜¶ï¼šCallback ç¼–ç¨‹æ¨¡å‹ï¼ˆçº¦ 25%ï¼‰

### 4.6 æ§åˆ¶å°å›è°ƒï¼ˆå¿«é€Ÿä¸Šæ‰‹ï¼‰
```typescript
// æ–‡ä»¶ï¼šsrc/ch04/console-callback.ts
import { ChatOpenAI } from "@langchain/openai";
import { ConsoleCallbackHandler } from "@langchain/core/callbacks/console";
import { PromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";

const prompt = PromptTemplate.fromTemplate("è§£é‡Šä¸€ä¸‹ {topic}ï¼Œè¦æ±‚ç®€æ´");
const model = new ChatOpenAI({
  modelName: "gpt-3.5-turbo",
  callbacks: [new ConsoleCallbackHandler()],
  verbose: true,
});

const chain = prompt.pipe(model).pipe(new StringOutputParser());

export async function run() {
  const out = await chain.invoke({ topic: "è™šæ‹Ÿåˆ—è¡¨ï¼ˆVirtualized Listï¼‰" });
  console.log("è¾“å‡º:\n", out);
}

if (require.main === module) run();
```

### 4.7 è‡ªå®šä¹‰ CallbackHandlerï¼ˆæ”¶é›†æŒ‡æ ‡/ä¸ŠæŠ¥è¿›åº¦ï¼‰
```typescript
// æ–‡ä»¶ï¼šsrc/ch04/metrics-callback.ts
import type { BaseCallbackHandler } from "@langchain/core/callbacks/base";

export class MetricsHandler implements BaseCallbackHandler {
  name = "metrics-handler";

  async handleLLMStart(event) {
    console.log("[LLMStart]", { runId: event.runId, model: event.invocationParams?.model });
  }

  async handleLLMNewToken(token, _idx, _runId, _parentRunId, _tags, data) {
    // å¯æ¨é€åˆ° SSE/WebSocket
    process.stdout.write(token);
  }

  async handleLLMEnd(event) {
    console.log("\n[LLMEnd] tokenUsage:", event?.output?.llmOutput?.tokenUsage);
  }

  async handleChainStart(event) {
    console.log("[ChainStart]", { runId: event.runId, name: event.name });
  }

  async handleChainEnd(event) {
    console.log("[ChainEnd]", { runId: event.runId, durationMs: event?.duration });
  }

  async handleChainError(err, _runId) {
    console.error("[ChainError]", err?.message);
  }
}
```

### 4.8 å°†è‡ªå®šä¹‰å›è°ƒæ³¨å…¥ Runnable
```typescript
// æ–‡ä»¶ï¼šsrc/ch04/with-metrics.ts
import { ChatOpenAI } from "@langchain/openai";
import { PromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { MetricsHandler } from "./metrics-callback";

const prompt = PromptTemplate.fromTemplate("å°†ä¸‹é¢æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼š{text}");
const model = new ChatOpenAI({ modelName: "gpt-3.5-turbo" });
const chain = prompt.pipe(model).pipe(new StringOutputParser());

export async function run() {
  const out = await chain.invoke(
    { text: "ä½ å¥½ï¼Œæ€§èƒ½ä¼˜åŒ–" },
    { callbacks: [new MetricsHandler()], tags: ["demo", "translate"] }
  );
  console.log("\nç»“æœ:\n", out);
}

if (require.main === module) run();
```

### 4.9 æµå¼è¾“å‡ºåˆ° CLIï¼ˆæ‰“å­—æœºæ•ˆæœï¼‰
```typescript
// æ–‡ä»¶ï¼šsrc/ch04/stream-cli.ts
import { ChatOpenAI } from "@langchain/openai";

const model = new ChatOpenAI({ modelName: "gpt-3.5-turbo", streaming: true });

export async function run() {
  const stream = await model.stream("è¯·ç”¨ 3 å¥è¯ä»‹ç» LangChain.js");
  for await (const chunk of stream) {
    process.stdout.write(chunk.content);
  }
  process.stdout.write("\n--- å®Œæˆ ---\n");
}

if (require.main === module) run();
```

### 4.10 å–æ¶ˆä¸è¶…æ—¶ï¼ˆAbortControllerï¼‰
```typescript
// æ–‡ä»¶ï¼šsrc/ch04/cancel.ts
import { ChatOpenAI } from "@langchain/openai";

export async function run() {
  const ctl = new AbortController();
  const model = new ChatOpenAI({ timeout: 20_000 });

  const p = model.invoke("è§£é‡Š SSR/CSR/SSG çš„åŒºåˆ«", { signal: ctl.signal });
  setTimeout(() => ctl.abort(), 200); // 200ms åå–æ¶ˆ

  try { await p; } catch (e) { console.log("å·²å–æ¶ˆ:", e.name); }
}

if (require.main === module) run();
```

---

## ğŸ”— Callback ä¸ Runnable/Memory/Agent çš„åä½œï¼ˆçº¦ 15%ï¼‰

### 4.11 Runnable å›è°ƒèåˆ
```typescript
// æ–‡ä»¶ï¼šsrc/ch04/runnable-callback.ts
import { RunnableSequence } from "@langchain/core/runnables";
import { PromptTemplate } from "@langchain/core/prompts";
import { ChatOpenAI } from "@langchain/openai";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { MetricsHandler } from "./metrics-callback";

const seq = RunnableSequence.from([
  PromptTemplate.fromTemplate("æ ¹æ®æçº²ç”Ÿæˆ 5 æ¡è¦ç‚¹ï¼š{outline}"),
  new ChatOpenAI({ temperature: 0.3 }),
  new StringOutputParser(),
]);

export async function run() {
  const text = await seq.invoke(
    { outline: "å‰ç«¯æ€§èƒ½ä¼˜åŒ–ï¼šèµ„æºã€æ¸²æŸ“ã€äº¤äº’ã€ç½‘ç»œã€ç›‘æ§" },
    { callbacks: [new MetricsHandler()], tags: ["outline"] }
  );
  console.log(text);
}

if (require.main === module) run();
```

### 4.12 Agent å·¥å…·è°ƒç”¨ä¸å›è°ƒ
åœ¨ Agent æ‰§è¡Œå·¥å…·ï¼ˆToolï¼‰æ—¶ï¼Œæ¯æ¬¡å·¥å…·è°ƒç”¨éƒ½å¯è§¦å‘ `handleToolStart/End`ï¼Œä¾¿äºè®°å½•â€œå·¥å…·åºåˆ—â€â€œå¤±è´¥é‡è¯•â€â€œè€—æ—¶/æˆæœ¬â€ã€‚è¿™å¯¹æ„å»ºâ€œä»»åŠ¡æ—¶é—´çº¿/å¯è§†åŒ–æ­¥éª¤â€å°¤ä¸ºå…³é”®ã€‚

ä¼ªä»£ç ï¼š
```typescript
// æ¯ä¸ª tool.execute å‰åæ‰“ç‚¹ï¼›å¯¹å¤±è´¥å·¥å…·è§¦å‘é‡è¯•ä¸å‘Šè­¦
```

### 4.13 Memory è¯»å†™ä¸ŠæŠ¥
åœ¨ `MessagesPlaceholder` æ³¨å…¥å†å²å‰åï¼Œé€šè¿‡å›è°ƒè®°å½•â€œæ³¨å…¥äº†å¤šå°‘æ¡å†å²â€â€œæ¥æºï¼ˆBuffer/Summary/Vectorï¼‰â€â€œToken å æ¯”â€ï¼Œä¾¿äºåç»­ä¼˜åŒ–ä¸æˆæœ¬æ§åˆ¶ã€‚

---

## ğŸŒ Next.js å®æ—¶æ¨é€ï¼šSSE ä¸ WebSocketï¼ˆçº¦ 15%ï¼‰

### 4.14 SSE æ¥å£ï¼ˆRoute Handlersï¼‰
```typescript
// æ–‡ä»¶ï¼šsrc/app/api/stream/route.ts ï¼ˆNext.js 14+ï¼‰
import { NextRequest } from "next/server";
import { ChatOpenAI } from "@langchain/openai";

export const runtime = "edge"; // è¾¹ç¼˜æ›´ä½å»¶è¿Ÿï¼ˆå¯é€‰ï¼‰

export async function POST(req: NextRequest) {
  const { question } = await req.json();
  const encoder = new TextEncoder();
  const stream = new ReadableStream({
    async start(controller) {
      const model = new ChatOpenAI({ modelName: "gpt-3.5-turbo", streaming: true });
      const s = await model.stream(question);
      for await (const chunk of s) {
        controller.enqueue(encoder.encode(`data: ${JSON.stringify({ t: chunk.content })}\n\n`));
      }
      controller.close();
    },
  });
  return new Response(stream, {
    headers: { "Content-Type": "text/event-stream", "Cache-Control": "no-cache" },
  });
}
```

### 4.15 å‰ç«¯æ¶ˆè´¹ï¼ˆæ‰“å­—æœº + å–æ¶ˆï¼‰
```tsx
// æ–‡ä»¶ï¼šsrc/app/page.tsx
"use client";
import { useEffect, useRef, useState } from "react";

export default function Page() {
  const [text, setText] = useState("");
  const esRef = useRef<EventSource | null>(null);

  const start = async () => {
    setText("");
    const res = await fetch("/api/stream", { method: "POST", body: JSON.stringify({ question: "ä»‹ç»LangChain" }) });
    const url = res.url; // åœ¨ edge ä¸‹å¯ç›´æ¥ä½¿ç”¨ res.body
    const es = new EventSource("/api/stream"); // è¿™é‡Œç®€åŒ–ï¼Œç”Ÿäº§åº”æ”¹ä¸ºç›´æ¥æ¶ˆè´¹ body æµ
    esRef.current = es;
    es.onmessage = (e) => {
      const { t } = JSON.parse(e.data);
      setText((prev) => prev + t);
    };
  };

  const stop = () => { esRef.current?.close(); };

  return (
    <main className="p-6 max-w-2xl mx-auto">
      <button onClick={start}>å¼€å§‹</button>
      <button onClick={stop} className="ml-2">åœæ­¢</button>
      <pre className="mt-4 whitespace-pre-wrap break-words">{text}</pre>
    </main>
  );
}
```

### 4.16 WebSocket æ–¹æ¡ˆï¼ˆæœåŠ¡å™¨æ¨é€å¤šç±»å‹äº‹ä»¶ï¼‰
```typescript
// æ–‡ä»¶ï¼šscripts/ws-server.tsï¼ˆNode ws ç®€åŒ–ç¤ºæ„ï¼‰
import { WebSocketServer } from "ws";
import { ChatOpenAI } from "@langchain/openai";

const wss = new WebSocketServer({ port: 8080 });
wss.on("connection", (ws) => {
  ws.on("message", async (msg) => {
    const { q } = JSON.parse(String(msg));
    const model = new ChatOpenAI({ streaming: true });
    const stream = await model.stream(q);
    ws.send(JSON.stringify({ type: "start" }));
    for await (const chunk of stream) ws.send(JSON.stringify({ type: "token", t: chunk.content }));
    ws.send(JSON.stringify({ type: "end" }));
  });
});
```

---

## ğŸ” ç›‘æ§ã€è¿½è¸ªä¸è¯„æµ‹ï¼ˆçº¦ 10%ï¼‰

### 4.17 LangSmith é›†æˆ
```bash
# .env
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=xxxx
LANGCHAIN_PROJECT=callback-demo
```

åœ¨å›è°ƒä¸­æ‰“æ ‡ `tags/metadata`ï¼Œå³å¯åœ¨ LangSmith ç«¯èšåˆæˆ Run æ ‘ã€æ€§èƒ½åˆ†å¸ƒä¸é”™è¯¯æ˜ç»†ã€‚

### 4.18 è‡ªå»ºæŒ‡æ ‡ä¸ŠæŠ¥
- å°†å›è°ƒäº‹ä»¶è½¬æˆç»“æ„åŒ– JSONï¼Œå†™å…¥ Kafka/ClickHouse/Elastic
- æŒ‡æ ‡ï¼šQPSã€P95/P99 å»¶è¿Ÿã€Token æˆæœ¬ã€é”™è¯¯ç‡ã€é‡è¯•ç‡ã€æˆåŠŸç‡
- æŠ¥è­¦ï¼šåŸºäºé˜ˆå€¼æˆ–å¼‚å¸¸æ£€æµ‹çš„å³æ—¶æé†’ï¼ˆSlack/é£ä¹¦/é’‰é’‰ï¼‰

### 4.19 A/B ä¸å›å½’è¯„æµ‹
- åŸºäº `tags` åœ¨ç”Ÿäº§ç¯å¢ƒåšç°åº¦ï¼šPromptA vs PromptBã€æ¨¡å‹åˆ‡æ¢
- åŸºäºâ€œå›ºå®šé—®é¢˜é›†â€åšå›å½’è¯„æµ‹ï¼Œç›‘æ§å›å½’ç‡

---

## ğŸš€ å®æˆ˜é¡¹ç›®ä¸€ï¼šå®æ—¶èŠå¤©ï¼ˆSSE + Callback è¿›åº¦ï¼‰çº¦ 15%

### 4.20 é¡¹ç›®ç›®æ ‡
- æ‰“å­—æœºæµå¼èŠå¤©ï¼›æ˜¾ç¤ºâ€œæ¨¡å‹æ€è€ƒä¸­/æ¶ˆè€— token/å½“å‰æ­¥éª¤â€
- æ”¯æŒå–æ¶ˆã€é‡è¯•ã€å¤åˆ¶ã€ç§»åŠ¨ç«¯é€‚é…

### 4.21 æ ¸å¿ƒå®ç°æ€è·¯
1) æœåŠ¡ç«¯ï¼šRoute Handler è¿”å› SSEï¼Œå°† `handleLLMNewToken` çš„ token é€æ¡å†™å…¥
2) å®¢æˆ·ç«¯ï¼šEventSource ç´¯ç§¯ token æ¸²æŸ“ï¼Œè¿›åº¦æ¡æ˜¾ç¤º `tokenUsage`
3) é”™è¯¯ï¼šè¿æ¥æ–­å¼€/è¶…æ—¶è‡ªåŠ¨é‡è¿ï¼›ä¿ç•™æœ€åæˆåŠŸå“åº”

### 4.22 å…³é”®ä»£ç ï¼ˆç•¥åŒ 4.14/4.15ï¼‰ï¼Œå¢åŠ è¿›åº¦äº‹ä»¶
```typescript
// æœåŠ¡ç«¯ token è®¡æ•°
let tokens = 0;
handlerLLMNewToken = () => { tokens++; push({ type: "progress", tokens }) };
```

### 4.23 ç§»åŠ¨ç«¯ä½“éªŒ
- è¾“å…¥æ¡†å¸åº•ã€è½¯é”®ç›˜å¼¹å‡ºé˜²é®æŒ¡
- é€æ­¥æ¸²æŸ“é¿å…ä¸»çº¿ç¨‹å¡é¡¿ï¼›é•¿æ–‡æœ¬æ–­è¡Œä¸åˆ†æ®µ append

---

## ğŸ§  å®æˆ˜é¡¹ç›®äºŒï¼šAgent æ­¥éª¤æ—¶é—´çº¿ï¼ˆCallback é©±åŠ¨ï¼‰çº¦ 15%

### 4.24 ç›®æ ‡
- å±•ç¤º Agent æ‰§è¡Œçš„â€œæ€è€ƒ-å·¥å…·-ç»“æœâ€æ—¶é—´çº¿ï¼›æ¯æ­¥è€—æ—¶ã€æ˜¯å¦é‡è¯•ã€æ˜¯å¦æˆåŠŸ
- å¯¹å¤±è´¥å·¥å…·è‡ªåŠ¨é‡è¯•ï¼Œè¶…æ—¶ç†”æ–­ï¼›æä¾›äººå·¥æ¥ç®¡å…¥å£

### 4.25 æ–¹æ¡ˆè¦ç‚¹
- åœ¨ `handleToolStart/End/Error` ä¸­å†™å…¥æ­¥éª¤äº‹ä»¶
- UI ç«¯è®¢é˜… WS/SSE æ¸²æŸ“å¡ç‰‡å¼æ­¥éª¤ï¼›å¤±è´¥é«˜äº®ä¸é‡è¯•æŒ‰é’®
- æŒä¹…åŒ–æ­¥éª¤æ—¥å¿—ï¼Œæ”¯æŒæœç´¢ä¸å›æ”¾

### 4.26 ä¼ªä»£ç 
```typescript
// server: on ToolStart -> ws.broadcast({ step: "search", status: "running" })
// on ToolEnd -> ws.broadcast({ step: "search", status: "done", duration })
// on ToolError -> ws.broadcast({ step: "search", status: "error", message })
```

---

## âš™ï¸ æ€§èƒ½ã€ç¨³å®šæ€§ä¸å®‰å…¨ï¼ˆçº¦ 5%ï¼‰

### 4.27 å»ºè®®
- å›è°ƒå¼‚æ­¥å¤„ç†ï¼Œé¿å…é˜»å¡ä¸»é“¾è·¯ï¼›æ‰¹é‡åˆ·æ–° UI äº‹ä»¶
- å¯¹å¤–æ¨é€å‰åšè„±æ•ï¼›ä¸è¦è®°å½•åŸå§‹å¯†é’¥/éšç§
- backpressure/å¿ƒè·³ä¿æ´»ï¼›æ–­çº¿è‡ªåŠ¨æ¢å¤
- ç»„ä»¶åŒ–ä¸ä¾èµ–æ³¨å…¥ï¼šå¯æ›¿æ¢çš„ Handlerï¼ˆConsole/Smith/Customï¼‰

---

## ğŸ§ª æµ‹è¯•ä¸è°ƒè¯•ï¼ˆçº¦ 5%ï¼‰

### 4.28 å›è°ƒå¯æµ‹è¯•æ€§
- ç”¨â€œå‡æ¨¡å‹/å‡å›è°ƒâ€æ¨¡æ‹Ÿäº‹ä»¶åºåˆ—ï¼Œæ–­è¨€ UI çŠ¶æ€å˜åŒ–
- Jestï¼šé€šè¿‡æ³¨å…¥ handlerï¼Œæ ¡éªŒ `handleLLMNewToken` è¢«è°ƒç”¨æ¬¡æ•°

### 4.29 å¸¸è§é—®é¢˜å®šä½
- æœªè§¦å‘å›è°ƒï¼šç¡®è®¤ `callbacks` æ³¨å…¥ä½ç½®ä¸ Runnable ç»„åˆé¡ºåº
- æµå¼å¡é¡¿ï¼šæ£€æŸ¥ Node/è¾¹ç¼˜è¿è¡Œæ—¶çš„æµå¼æ”¯æŒä¸ flush æ–¹å¼
- Token ç»Ÿè®¡ä¸å‡†ï¼šä¸åŒæä¾›å•†çš„è¿”å›å·®å¼‚ï¼Œç»Ÿä¸€è½¬ä¹‰

---

## ğŸ“š å‚è€ƒä¸æ‰©å±•
- LangChain.js å›è°ƒæ–‡æ¡£ï¼š`https://js.langchain.com/`
- LangSmithï¼š`https://docs.smith.langchain.com/`
- SSE æ ‡å‡†ï¼š`https://developer.mozilla.org/docs/Web/API/Server-sent_events/Using_server-sent_events`
- WebSocketï¼š`https://developer.mozilla.org/docs/Web/API/WebSockets_API`

---

## âœ… æœ¬ç« å°ç»“
- æŒæ¡äº† Callback ç”Ÿå‘½å‘¨æœŸã€Run æ ‘ä¸äº‹ä»¶é©±åŠ¨è®¾è®¡
- å®ç°äº†æ§åˆ¶å°/è‡ªå®šä¹‰å›è°ƒã€æµå¼è¾“å‡ºã€å–æ¶ˆä¸è¶…æ—¶
- åœ¨ Next.js ä¸­å®Œæˆäº† SSE/WS çš„å®æ—¶æ¨é€ä¸å‰ç«¯æ‰“å­—æœº
- æ„å»ºäº†â€œå®æ—¶èŠå¤©â€å’Œâ€œAgent æ—¶é—´çº¿â€ä¸¤ä¸ªå®æˆ˜æ ·ä¾‹
- å¼•å…¥ç›‘æ§è¿½è¸ªã€A/B ä¸æˆæœ¬/ç¨³å®šæ€§ä¼˜åŒ–ç­–ç•¥

## ğŸ¯ ä¸‹ç« é¢„å‘Š
ä¸‹ä¸€ç« ã€ŠRunnable æ¥å£ä¸ä»»åŠ¡ç¼–æ’ç³»ç»Ÿã€‹ä¸­ï¼Œæˆ‘ä»¬å°†ï¼š
- æ·±å…¥ Runnable çš„ç»„åˆã€åˆ†æ”¯ã€å¹¶è¡Œä¸ç¼“å­˜
- å°†å¤æ‚å·¥ä½œæµæŠ½è±¡ä¸ºå¯å¤ç”¨çš„æµæ°´çº¿
- ä¸ LangGraph çŠ¶æ€å›¾è”åŠ¨ï¼Œæ„å»ºä¼ä¸šçº§ç¼–æ’

> æœ€åæ„Ÿè°¢é˜…è¯»ï¼æ¬¢è¿å…³æ³¨æˆ‘ï¼Œå¾®ä¿¡å…¬ä¼—å·ï¼š`ã€Šé²«å°é±¼ä¸æ­£ç»ã€‹`ã€‚æ¬¢è¿ç‚¹èµã€æ”¶è—ã€å…³æ³¨ï¼Œä¸€é”®ä¸‰è¿ï¼ï¼ï¼
