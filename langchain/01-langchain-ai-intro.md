# ç¬¬1ç« ï¼šLangChain.js ä¸ AI åº”ç”¨å¼€å‘å…¥é—¨

## ğŸ¯ æœ¬ç« ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œæ‚¨å°†ï¼š
- ç†è§£ LangChain.js çš„æ ¸å¿ƒæ¦‚å¿µå’Œè®¾è®¡ç†å¿µ
- æŒæ¡ LangChain.js çš„å®‰è£…å’ŒåŸºç¡€é…ç½®
- äº†è§£ AI åº”ç”¨å¼€å‘çš„åŸºæœ¬æµç¨‹
- å®Œæˆç¬¬ä¸€ä¸ª LangChain.js åº”ç”¨
- ç†è§£ LangChain.js åœ¨ AI ç”Ÿæ€ç³»ç»Ÿä¸­çš„å®šä½

## ğŸ“– ä»€ä¹ˆæ˜¯ LangChain.js

### å®šä¹‰ä¸æ ¸å¿ƒç†å¿µ

LangChain.js æ˜¯ä¸€ä¸ªä¸“ä¸ºæ„å»ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨è€Œè®¾è®¡çš„ JavaScript/TypeScript æ¡†æ¶ã€‚å®ƒçš„æ ¸å¿ƒç†å¿µæ˜¯è®©å¼€å‘è€…èƒ½å¤Ÿè½»æ¾åœ°å°† LLM ä¸å…¶ä»–æ•°æ®æºå’Œè®¡ç®—èµ„æºè¿æ¥èµ·æ¥ï¼Œæ„å»ºæ™ºèƒ½ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„åº”ç”¨ç¨‹åºã€‚

### æ ¸å¿ƒç‰¹æ€§

ğŸ”— **é“¾å¼ç»„åˆï¼ˆChainingï¼‰**
- å°†å¤šä¸ªç»„ä»¶ä¸²è”èµ·æ¥ï¼Œå½¢æˆå¤æ‚çš„å¤„ç†æµç¨‹
- æ”¯æŒæ¡ä»¶åˆ†æ”¯å’Œå¹¶è¡Œå¤„ç†
- æä¾›ä¸°å¯Œçš„é¢„æ„å»ºé“¾æ¨¡æ¿

ğŸ§  **è®°å¿†ç®¡ç†ï¼ˆMemoryï¼‰**
- ç»´æŠ¤å¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡çŠ¶æ€
- æ”¯æŒå¤šç§è®°å¿†ç­–ç•¥ï¼ˆçŸ­æœŸã€é•¿æœŸã€æ‘˜è¦ç­‰ï¼‰
- è‡ªåŠ¨ç®¡ç† token é™åˆ¶å’Œæˆæœ¬ä¼˜åŒ–

ğŸ”Œ **æ¨¡å—åŒ–è®¾è®¡**
- å¯æ’æ‹”çš„ç»„ä»¶æ¶æ„
- æ”¯æŒè‡ªå®šä¹‰ç»„ä»¶å¼€å‘
- ä¸°å¯Œçš„ç¬¬ä¸‰æ–¹é›†æˆ

âš¡ **å¼‚æ­¥ä¼˜å…ˆ**
- åŸç”Ÿæ”¯æŒ Promise å’Œ async/await
- æµå¼å¤„ç†å’Œå®æ—¶å“åº”
- é«˜æ€§èƒ½å¹¶å‘å¤„ç†

## ğŸ—ï¸ LangChain.js æ¶æ„æ¦‚è§ˆ

### æ ¸å¿ƒç»„ä»¶å±‚æ¬¡

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           åº”ç”¨å±‚ (Applications)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           é“¾å±‚ (Chains)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         ç»„ä»¶å±‚ (Components)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Models  â”‚ Prompts â”‚   Memory    â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚ Indexes â”‚ Agents  â”‚ Callbacks   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          åŸºç¡€å±‚ (Foundation)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



### ä¸»è¦æ¨¡å—è¯´æ˜

**ğŸ¤– Modelsï¼ˆæ¨¡å‹å±‚ï¼‰**
- LLM æ¥å£ï¼šOpenAIã€Anthropicã€Hugging Face ç­‰
- Chat Modelsï¼šä¸“é—¨ç”¨äºå¯¹è¯çš„æ¨¡å‹æ¥å£
- Embeddingsï¼šæ–‡æœ¬å‘é‡åŒ–æ¨¡å‹

**ğŸ“ Promptsï¼ˆæç¤ºå±‚ï¼‰**
- Prompt Templatesï¼šåŠ¨æ€æç¤ºæ¨¡æ¿
- Few-shot Examplesï¼šå°‘æ ·æœ¬å­¦ä¹ ç¤ºä¾‹
- Output Parsersï¼šç»“æ„åŒ–è¾“å‡ºè§£æ

**ğŸ§  Memoryï¼ˆè®°å¿†å±‚ï¼‰**
- Conversation Memoryï¼šå¯¹è¯è®°å¿†
- Vector Store Memoryï¼šå‘é‡å­˜å‚¨è®°å¿†
- Summary Memoryï¼šæ‘˜è¦è®°å¿†

**ğŸ” Indexesï¼ˆç´¢å¼•å±‚ï¼‰**
- Document Loadersï¼šæ–‡æ¡£åŠ è½½å™¨
- Text Splittersï¼šæ–‡æœ¬åˆ†å‰²å™¨
- Vector Storesï¼šå‘é‡æ•°æ®åº“

**ğŸ¤– Agentsï¼ˆä»£ç†å±‚ï¼‰**
- Tool Integrationï¼šå·¥å…·é›†æˆ
- Decision Makingï¼šå†³ç­–åˆ¶å®š
- Action Executionï¼šåŠ¨ä½œæ‰§è¡Œ

## ğŸ› ï¸ ç¯å¢ƒæ­å»ºä¸å®‰è£…

### ç³»ç»Ÿè¦æ±‚

- **Node.js**: 18.0.0 æˆ–æ›´é«˜ç‰ˆæœ¬
- **npm**: 8.0.0 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼ˆæˆ– yarn 1.22.0+ï¼‰
- **TypeScript**: 4.5.0 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼ˆæ¨èï¼‰

### åˆ›å»ºæ–°é¡¹ç›®

```bash
# 1. åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir langchain-tutorial
cd langchain-tutorial

# 2. åˆå§‹åŒ– npm é¡¹ç›®
npm init -y

# 3. å®‰è£… TypeScript å¼€å‘ç¯å¢ƒ
npm install -D typescript @types/node tsx nodemon

# 4. åˆ›å»º TypeScript é…ç½®
npx tsc --init
```

### å®‰è£… LangChain.js

```bash
# æ ¸å¿ƒåŒ…
npm install @langchain/core

# ç¤¾åŒºé›†æˆåŒ…
npm install @langchain/community

# OpenAI é›†æˆ
npm install @langchain/openai

# å…¶ä»–å¸¸ç”¨é›†æˆ
npm install @langchain/anthropic
npm install @langchain/google-genai
npm install @langchain/huggingface
```

### é…ç½® TypeScript

æ›´æ–° `tsconfig.json`ï¼š

```json
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "commonjs",
    "lib": ["ES2020"],
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
```

### ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# OpenAI API é…ç½®
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic API é…ç½®
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# å…¶ä»–é…ç½®
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_api_key_here
```

å®‰è£…ç¯å¢ƒå˜é‡æ”¯æŒï¼š

```bash
npm install dotenv
```

## ğŸš€ ç¬¬ä¸€ä¸ª LangChain.js åº”ç”¨

### åŸºç¡€ç¤ºä¾‹ï¼šç®€å•å¯¹è¯

åˆ›å»º `src/basic-chat.ts`ï¼š

```typescript
import { ChatOpenAI } from "@langchain/openai";
import { HumanMessage, SystemMessage } from "@langchain/core/messages";
import * as dotenv from "dotenv";

// åŠ è½½ç¯å¢ƒå˜é‡
dotenv.config();

// åˆå§‹åŒ–æ¨¡å‹
const model = new ChatOpenAI({
  openAIApiKey: process.env.OPENAI_API_KEY,
  modelName: "gpt-3.5-turbo",
  temperature: 0.7,
  maxTokens: 1000,
});

async function basicChat() {
  try {
    // åˆ›å»ºæ¶ˆæ¯
    const messages = [
      new SystemMessage("ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‰ç«¯å¼€å‘åŠ©æ‰‹ï¼Œæ“…é•¿ JavaScript å’Œ React å¼€å‘ã€‚"),
      new HumanMessage("è¯·è§£é‡Šä»€ä¹ˆæ˜¯ React Hooksï¼Œå¹¶ç»™å‡ºä¸€ä¸ªç®€å•çš„ä½¿ç”¨ç¤ºä¾‹ã€‚")
    ];

    // å‘é€è¯·æ±‚å¹¶è·å–å“åº”
    const response = await model.invoke(messages);

    console.log("AI åŠ©æ‰‹å›å¤ï¼š");
    console.log(response.content);

  } catch (error) {
    console.error("å‘ç”Ÿé”™è¯¯ï¼š", error);
  }
}

// è¿è¡Œç¤ºä¾‹
basicChat();
```

### ä½¿ç”¨ Prompt æ¨¡æ¿

åˆ›å»º `src/prompt-template.ts`ï¼š

```typescript
import { ChatOpenAI } from "@langchain/openai";
import { PromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import * as dotenv from "dotenv";

dotenv.config();

const model = new ChatOpenAI({
  openAIApiKey: process.env.OPENAI_API_KEY,
  modelName: "gpt-3.5-turbo",
});

// åˆ›å»º Prompt æ¨¡æ¿
const promptTemplate = PromptTemplate.fromTemplate(`
ä½ æ˜¯ä¸€ä¸ª{role}ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·è§£å†³{domain}ç›¸å…³çš„é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·æä¾›è¯¦ç»†ã€ä¸“ä¸šçš„å›ç­”ï¼ŒåŒ…å«ä»¥ä¸‹è¦ç´ ï¼š
1. é—®é¢˜åˆ†æ
2. è§£å†³æ–¹æ¡ˆ
3. ä»£ç ç¤ºä¾‹ï¼ˆå¦‚æœé€‚ç”¨ï¼‰
4. æœ€ä½³å®è·µå»ºè®®

å›ç­”ï¼š
`);

// åˆ›å»ºè¾“å‡ºè§£æå™¨
const outputParser = new StringOutputParser();

// æ„å»ºå¤„ç†é“¾
const chain = promptTemplate.pipe(model).pipe(outputParser);

async function promptTemplateExample() {
  try {
    const result = await chain.invoke({
      role: "èµ„æ·±å‰ç«¯å·¥ç¨‹å¸ˆ",
      domain: "React æ€§èƒ½ä¼˜åŒ–",
      question: "å¦‚ä½•ä¼˜åŒ– React åº”ç”¨çš„æ¸²æŸ“æ€§èƒ½ï¼Ÿ"
    });

    console.log("ä¼˜åŒ–å»ºè®®ï¼š");
    console.log(result);

  } catch (error) {
    console.error("å¤„ç†å¤±è´¥ï¼š", error);
  }
}

promptTemplateExample();
```

### æµå¼å“åº”å¤„ç†

åˆ›å»º `src/streaming-response.ts`ï¼š

```typescript
import { ChatOpenAI } from "@langchain/openai";
import { HumanMessage } from "@langchain/core/messages";
import * as dotenv from "dotenv";

dotenv.config();

const model = new ChatOpenAI({
  openAIApiKey: process.env.OPENAI_API_KEY,
  modelName: "gpt-3.5-turbo",
  streaming: true, // å¯ç”¨æµå¼å“åº”
});

async function streamingExample() {
  try {
    console.log("AI æ­£åœ¨æ€è€ƒä¸­...");
    console.log("å›å¤ï¼š");

    const stream = await model.stream([
      new HumanMessage("è¯·è¯¦ç»†ä»‹ç» LangChain.js çš„ä¸»è¦ç‰¹æ€§å’Œä½¿ç”¨åœºæ™¯ã€‚")
    ]);

    // é€å—å¤„ç†æµå¼å“åº”
    for await (const chunk of stream) {
      process.stdout.write(chunk.content);
    }

    console.log("\n\n--- å›å¤å®Œæˆ ---");

  } catch (error) {
    console.error("æµå¼å¤„ç†å¤±è´¥ï¼š", error);
  }
}

streamingExample();
```

### è¿è¡Œè„šæœ¬

æ›´æ–° `package.json` æ·»åŠ è¿è¡Œè„šæœ¬ï¼š

```json
{
  "scripts": {
    "dev": "tsx watch src/index.ts",
    "build": "tsc",
    "start": "node dist/index.js",
    "basic-chat": "tsx src/basic-chat.ts",
    "prompt-template": "tsx src/prompt-template.ts",
    "streaming": "tsx src/streaming-response.ts"
  }
}
```

è¿è¡Œç¤ºä¾‹ï¼š

```bash
# è¿è¡ŒåŸºç¡€å¯¹è¯ç¤ºä¾‹
npm run basic-chat

# è¿è¡Œ Prompt æ¨¡æ¿ç¤ºä¾‹
npm run prompt-template

# è¿è¡Œæµå¼å“åº”ç¤ºä¾‹
npm run streaming
```

## ğŸ”§ æ ¸å¿ƒæ¦‚å¿µæ·±å…¥

### 1. Runnable æ¥å£

LangChain.js ä¸­çš„æ‰€æœ‰ç»„ä»¶éƒ½å®ç°äº† `Runnable` æ¥å£ï¼Œè¿™æ˜¯æ¡†æ¶çš„æ ¸å¿ƒæŠ½è±¡ï¼š

```typescript
interface Runnable<Input, Output> {
  invoke(input: Input): Promise<Output>;
  stream(input: Input): AsyncGenerator<Output>;
  batch(inputs: Input[]): Promise<Output[]>;
  pipe<NewOutput>(next: Runnable<Output, NewOutput>): Runnable<Input, NewOutput>;
}
```

### 2. é“¾å¼ç»„åˆï¼ˆChainingï¼‰

```typescript
import { PromptTemplate } from "@langchain/core/prompts";
import { ChatOpenAI } from "@langchain/openai";
import { StringOutputParser } from "@langchain/core/output_parsers";

// åˆ›å»ºå¤„ç†é“¾
const prompt = PromptTemplate.fromTemplate("ç¿»è¯‘ä»¥ä¸‹æ–‡æœ¬åˆ°{language}ï¼š{text}");
const model = new ChatOpenAI();
const parser = new StringOutputParser();

// ä½¿ç”¨ pipe æ–¹æ³•ç»„åˆ
const translationChain = prompt.pipe(model).pipe(parser);

// ä½¿ç”¨é“¾
const result = await translationChain.invoke({
  language: "è‹±æ–‡",
  text: "ä½ å¥½ï¼Œä¸–ç•Œï¼"
});
```

### 3. é”™è¯¯å¤„ç†å’Œé‡è¯•

```typescript
import { ChatOpenAI } from "@langchain/openai";
import { HumanMessage } from "@langchain/core/messages";

const model = new ChatOpenAI({
  maxRetries: 3, // æœ€å¤§é‡è¯•æ¬¡æ•°
  timeout: 30000, // è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
});

async function robustChat() {
  try {
    const response = await model.invoke([
      new HumanMessage("è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†")
    ]);

    console.log(response.content);
  } catch (error) {
    if (error.name === 'TimeoutError') {
      console.error("è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•");
    } else if (error.status === 429) {
      console.error("API è°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œè¯·ç¨åé‡è¯•");
    } else {
      console.error("æœªçŸ¥é”™è¯¯ï¼š", error.message);
    }
  }
}
```

## ğŸ“Š å®é™…åº”ç”¨åœºæ™¯

### 1. æ™ºèƒ½å®¢æœåŠ©æ‰‹

```typescript
import { ChatOpenAI } from "@langchain/openai";
import { PromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";

class CustomerServiceBot {
  private chain;

  constructor() {
    const prompt = PromptTemplate.fromTemplate(`
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ï¼š

    å…¬å¸ä¿¡æ¯ï¼š{companyInfo}
    ç”¨æˆ·é—®é¢˜ï¼š{userQuestion}
    ç”¨æˆ·å†å²ï¼š{userHistory}

    è¯·æä¾›å‹å¥½ã€ä¸“ä¸šçš„å›ç­”ï¼š
    `);

    const model = new ChatOpenAI({
      modelName: "gpt-3.5-turbo",
      temperature: 0.3, // è¾ƒä½çš„æ¸©åº¦ç¡®ä¿å›ç­”ä¸€è‡´æ€§
    });

    this.chain = prompt.pipe(model).pipe(new StringOutputParser());
  }

  async handleUserQuery(question: string, userHistory: string = "") {
    return await this.chain.invoke({
      companyInfo: "æˆ‘ä»¬æ˜¯ä¸€å®¶ä¸“ä¸šçš„è½¯ä»¶å¼€å‘å…¬å¸ï¼Œæä¾› Web å’Œç§»åŠ¨åº”ç”¨å¼€å‘æœåŠ¡ã€‚",
      userQuestion: question,
      userHistory: userHistory
    });
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const bot = new CustomerServiceBot();
const response = await bot.handleUserQuery("ä½ ä»¬çš„æœåŠ¡ä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿ");
console.log(response);
```

### 2. ä»£ç å®¡æŸ¥åŠ©æ‰‹

```typescript
import { ChatOpenAI } from "@langchain/openai";
import { PromptTemplate } from "@langchain/core/prompts";

class CodeReviewAssistant {
  private model;
  private reviewPrompt;

  constructor() {
    this.model = new ChatOpenAI({
      modelName: "gpt-4", // ä½¿ç”¨æ›´å¼ºçš„æ¨¡å‹è¿›è¡Œä»£ç å®¡æŸ¥
      temperature: 0.1,
    });

    this.reviewPrompt = PromptTemplate.fromTemplate(`
    è¯·å®¡æŸ¥ä»¥ä¸‹ {language} ä»£ç ï¼Œå¹¶æä¾›è¯¦ç»†çš„åé¦ˆï¼š

    ä»£ç ï¼š
    \`\`\`{language}
    {code}
    \`\`\`

    è¯·ä»ä»¥ä¸‹æ–¹é¢è¿›è¡Œè¯„ä¼°ï¼š
    1. ä»£ç è´¨é‡å’Œå¯è¯»æ€§
    2. æ€§èƒ½ä¼˜åŒ–å»ºè®®
    3. å®‰å…¨æ€§è€ƒè™‘
    4. æœ€ä½³å®è·µå»ºè®®
    5. æ½œåœ¨çš„ bug æˆ–é—®é¢˜

    å®¡æŸ¥æŠ¥å‘Šï¼š
    `);
  }

  async reviewCode(code: string, language: string = "javascript") {
    const chain = this.reviewPrompt.pipe(this.model);

    const result = await chain.invoke({
      code,
      language
    });

    return result.content;
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const reviewer = new CodeReviewAssistant();
const codeToReview = `
function calculateTotal(items) {
  let total = 0;
  for (let i = 0; i < items.length; i++) {
    total += items[i].price * items[i].quantity;
  }
  return total;
}
`;

const review = await reviewer.reviewCode(codeToReview, "javascript");
console.log(review);
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. API å¯†é’¥ç®¡ç†

```typescript
// âŒ é”™è¯¯åšæ³•ï¼šç¡¬ç¼–ç  API å¯†é’¥
const model = new ChatOpenAI({
  openAIApiKey: "sk-...", // æ°¸è¿œä¸è¦è¿™æ ·åšï¼
});

// âœ… æ­£ç¡®åšæ³•ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡
const model = new ChatOpenAI({
  openAIApiKey: process.env.OPENAI_API_KEY,
});

// âœ… æ›´å¥½çš„åšæ³•ï¼šæ·»åŠ éªŒè¯
if (!process.env.OPENAI_API_KEY) {
  throw new Error("OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®");
}
```

### 2. æˆæœ¬æ§åˆ¶

```typescript
const model = new ChatOpenAI({
  modelName: "gpt-3.5-turbo", // é€‰æ‹©åˆé€‚çš„æ¨¡å‹
  maxTokens: 500, // é™åˆ¶è¾“å‡ºé•¿åº¦
  temperature: 0.7, // é€‚å½“çš„éšæœºæ€§
});

// ç›‘æ§ token ä½¿ç”¨
const response = await model.invoke(messages, {
  callbacks: [{
    handleLLMEnd: (output) => {
      console.log(`Token ä½¿ç”¨æƒ…å†µ:`, output.llmOutput?.tokenUsage);
    }
  }]
});
```

### 3. é”™è¯¯å¤„ç†ç­–ç•¥

```typescript
class RobustLLMService {
  private model;
  private maxRetries = 3;
  private retryDelay = 1000;

  constructor() {
    this.model = new ChatOpenAI({
      maxRetries: this.maxRetries,
      timeout: 30000,
    });
  }

  async safeInvoke(messages: any[], retryCount = 0): Promise<string> {
    try {
      const response = await this.model.invoke(messages);
      return response.content;
    } catch (error) {
      if (retryCount < this.maxRetries) {
        console.log(`é‡è¯•ç¬¬ ${retryCount + 1} æ¬¡...`);
        await this.delay(this.retryDelay * Math.pow(2, retryCount)); // æŒ‡æ•°é€€é¿
        return this.safeInvoke(messages, retryCount + 1);
      }
      throw error;
    }
  }

  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

## ğŸ” è°ƒè¯•å’Œç›‘æ§

### å¯ç”¨è¯¦ç»†æ—¥å¿—

```typescript
import { ChatOpenAI } from "@langchain/openai";
import { ConsoleCallbackHandler } from "@langchain/core/callbacks/console";

const model = new ChatOpenAI({
  callbacks: [new ConsoleCallbackHandler()], // å¯ç”¨æ§åˆ¶å°æ—¥å¿—
  verbose: true, // è¯¦ç»†æ¨¡å¼
});
```

### ä½¿ç”¨ LangSmith è¿½è¸ª

```bash
# åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ 
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_api_key
LANGCHAIN_PROJECT=your_project_name
```

## ğŸ“š æœ¬ç« æ€»ç»“

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œæˆ‘ä»¬æŒæ¡äº†ï¼š

âœ… **æ ¸å¿ƒæ¦‚å¿µç†è§£**
- LangChain.js çš„è®¾è®¡ç†å¿µå’Œæ¶æ„
- Runnable æ¥å£å’Œé“¾å¼ç»„åˆ
- ä¸»è¦ç»„ä»¶çš„ä½œç”¨å’Œå…³ç³»

âœ… **å®è·µæŠ€èƒ½è·å¾—**
- ç¯å¢ƒæ­å»ºå’Œé¡¹ç›®é…ç½®
- åŸºç¡€ API è°ƒç”¨å’Œå“åº”å¤„ç†
- Prompt æ¨¡æ¿çš„ä½¿ç”¨
- æµå¼å“åº”çš„å¤„ç†

âœ… **æœ€ä½³å®è·µæŒæ¡**
- API å¯†é’¥å®‰å…¨ç®¡ç†
- é”™è¯¯å¤„ç†å’Œé‡è¯•ç­–ç•¥
- æˆæœ¬æ§åˆ¶å’Œæ€§èƒ½ä¼˜åŒ–
- è°ƒè¯•å’Œç›‘æ§æ–¹æ³•

## ğŸ¯ ä¸‹ç« é¢„å‘Š

åœ¨ä¸‹ä¸€ç« ã€ŠPrompt Engineering ä¸æ¨¡æ¿ç³»ç»Ÿæ·±åº¦å®è·µã€‹ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ï¼š

- Prompt è®¾è®¡çš„è‰ºæœ¯ä¸ç§‘å­¦
- é«˜çº§æ¨¡æ¿æŠ€æœ¯å’ŒåŠ¨æ€ç”Ÿæˆ
- Few-shot Learning å’Œ Chain-of-Thought
- è¾“å‡ºè§£æå’Œç»“æ„åŒ–æ•°æ®å¤„ç†
- Prompt ä¼˜åŒ–å’Œ A/B æµ‹è¯•
